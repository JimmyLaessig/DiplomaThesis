\chapter{Introduction}

\section{Motivation}

In recent years, multiple acquisition devices and methods of point clouds from real objects have emerged, such as laser scanners, LIDAR, Microsoft Kinect, or photogrammetric reconstructions. The fields of applications for point clouds include, but are not limited to, documenting geomorphological erosion, monitoring urban and agricultural developments, mapping archeological sites, and generating assets for the entertainment industry. The acquisition techniques produce highly detailed point clouds that contain several millions of points. This enormous data resolution presents several challenges to both the system and the user. 

\par

% Challenges to the system
The size of point-cloud datasets has increased at such a rapid rate that they are now simply too large to fit into system memory, let alone graphics card memory. Therefore, new solutions for out-of-core representations have emerged. In most of these solutions, the point cloud data is cached in one or more structured files on the hard drive and can therefore not be accessed directly. Based on a culling heuristic, chunks of point-cloud data are loaded into memory as needed. This continuous swapping of data yields the disk speed as a potential bottleneck when it comes to performance. However, it also introduces the benefit of only storing chunks of data in memory that are of immediate interest to the user. 

\par

% Challenges to the user
Point-cloud datasets commonly lack structure and contain a lot of unneeded data. Thus, additional processing is required to enrich the data set with semantic information. To improve data quality, additional postprocessing steps must be performed by the user manually, such as removing imperfect regions, extracting regions of interest. However, achieving this task by using classic two-dimensional interaction metaphors can be tedious and cumbersome as the system cannot predict the desired boundaries of the third dimension of the interaction. Without the use of more semantic information, such as the geometric shape of the region of interest, multiple view changes might be necessary to only select desired regions from the three-dimensional scene. 

\par

% Lack of semantic information
A way of introducing semantic information into unstructured point-cloud data is shape detection. The objective is to find regions in point clouds with similar characteristics, such as local curvature and neighborhoods, to help the user understand local and global structures. Current solutions, as presented by Schnabel et al. \cite{schnabel-2007-efficient, schnabel-2007-ransac}, can already produce a precise segmentation of point clouds. The complexity of these algorithms increases with the size of the point cloud, making the computation for billions of points infeasible in real time. However, when looking at raw numbers, the approach delivers promising results in a fraction of a second for point clouds of smaller size (<12,000 points).

\par

This thesis proposes a user-controlled technique for shape detection in small local regions of point clouds. This approach can to deliver semantic information on the local geometry in interactive time. This information is used to improve ordinary two-dimensional interaction metaphors by limiting the set of points available for interaction to those that belong to the selected shape (i.e. closely follow the curvature of the shape). 


\section{Problem Definition}

Modern point clouds can contain millions of points with it's size often exceeding several gigabytes. Usually, consumer PCs do not have the memory capacity to hold the entire point cloud in system memory or video memory. Efficient out-of-core solutions for point clouds are discussed in numerous publications, Scheibelbauer \cite{scheiblauer-thesis}, Elseberg et al. \cite{elseberg2013one} or the Point Cloud Library \cite{rusu20113d}, to only name a few. However, a custom solution is needed that stores point clouds enriched with semantic information.

\par

In scans of urban environments, many structures can be represented in a more memory-efficient way. Points that follow a wall can often be compressed to few triangles. Pillars often share similarities with cylinders. Detecting such shapes is an immense task that scales with the number of points and fails to be executed in real time. When exploring a point cloud, immediate feedback of local geometry is useful, since it introduces additional information to the user. This task cannot be achieved without substantial postprocessing of the point cloud. 

\par

Common two-dimensional interaction metaphors (e.g. mouse) are useful tools when selecting or picking regions from a two-dimensional context. When porting these techniques to 3D, the third dimension (i.e. depth) must be guessed or controlled separately. A region of interest usually is a set of points that are spatial neighboring and create a structural element in the point cloud. Ideally, the selection of such a region is performed by defining a minimal enclosing volume that contains all points. Achieving this selection by using 2D-interaction metaphors only is challenging, as the techniques do not know the desired depth boundaries of the selection region. Therefore, interactions across multiple views are needed to achieve this selection. Methods that use 3D information, such as the volumetric brush presented by Weyrich et al. \cite{weyrich2004post}, can ease selection tasks. By consulting the depth buffer each frame, the brush follows the curvature of the furthermost geometry. However, by reading pixels from the GPU, the rendering process is stalled. This technique reacts to occlusion such that the brush follows the geometry depicted in the depth buffer, rather then the desired structure. Thus, view changes are still required.


\section{Contributions}

The main contribution of this diploma thesis is the implementation of a semi-automated procedure to detect shapes in multiple levels of detail in point clouds. Instead of performing shape detection on the entire point cloud at once, our approach lets the user control the region in which shapes should be detected. By reducing those regions to a suitable size, a well-known shape detection algorithm can return meaningful results in interactive time, such that the user is presented with immediate feedback on the local geometry of the selected region. 

\par

The size of detected shapes is limited to the region in which it was detected. A clustering algorithm finds shapes from different different regions and levels of detail, based on a similarity heuristic, and creates a larger connected cluster of shapes. This cluster is used to present geometric information on a larger scale to the user, rather than each shape separately. 

\par

This thesis proposes several improvements to commonly known user interactions. \textit{Point picking} and \textit{region selection} are improved by consulting the local geometry of the point cloud to assist the user. By using a shape as support, the interaction dimensions are reduced to the parameter space of the shapes, allowing the user to exclude unwanted points from interactions easily. 
Additionally, a novel interaction technique is introduced that allows the user to increment the level of detail locally along a shape. This helps the user to explore the structure of the point cloud in more detail. 


\section{Structure of the Work}

Chapter \ref{chap:related_work} covers the related work for this thesis, including point-cloud rendering and out-of-core representations, shape detection, and segmentation and advanced user interactions on point clouds. Chapter \ref{chap:octree} describes the octree used for the out-of-core representation of the point cloud, as well as some metrics that further describe the content of an octree node. Chapter \ref{chap:shapeDetection} describes the algorithms used to detect primitive shapes in a point cloud and proposes a technique to cluster similar shapes into one coherent shape cluster for user interactions. Chapter \ref{chap:systemDesign} discusses the application's features, including the user-controlled shape detection and assisted interactions that utilize the detected shapes as support shape. Chapter \ref{chap:implementation} focuses on implementation details in a functional context. Results of the application are presented in Chapter \ref{chap:results} along with performance benchmarks of the presented interactions. Chapter \ref{chap:conclusion} concludes this thesis with a reflection on the application and an outlook on future work. 
